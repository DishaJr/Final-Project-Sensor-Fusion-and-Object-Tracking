# Final-Project-Sensor-Fusion-and-Object-Tracking

## **Task :**

* Implement an EKF to track a single real-world target with lidar measurement input over time.
* Implement the track management to initialize and delete tracks, set a track state and a track score.
* Implement a single nearest neighbor data association to associate measurements to tracks.
* Implement the nonlinear camera measurement model.

#

In each step a set of instructions are followed which are set in Udacity's project instructions tabs as well as providing the TODO's to each file. The result of following these steps can be seen below.

**Step 1 :**

![Figure_1](https://github.com/DishaJr/Final-Project-Sensor-Fusion-and-Object-Tracking/blob/main/AAAA)

**Step 2 :**

![Figure_2](https://github.com/DishaJr/Final-Project-Sensor-Fusion-and-Object-Tracking/blob/main/Screenshot%20from%202023-05-07%2011-20-16.png)

**Step 3 :**

![Figure_!](https://github.com/DishaJr/Final-Project-Sensor-Fusion-and-Object-Tracking/blob/main/AAAA)

**Step 4 :**

![Figure_!](https://github.com/DishaJr/Final-Project-Sensor-Fusion-and-Object-Tracking/blob/main/AAAA)

#


* Do you see any benefits in camera-lidar fusion compared to lidar-only tracking (in theory and in your concrete results)?
* Which challenges will a sensor fusion system face in real-life scenarios? Did you see any of these challenges in the project?
* Can you think of ways to improve your tracking results in the future?
